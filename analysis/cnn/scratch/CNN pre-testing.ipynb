{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = False  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=config)\n",
    "\n",
    "tf.keras.backend.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "1e-07\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.backend.set_floatx('float16')\n",
    "# tf.keras.backend.set_epsilon(1e-3)\n",
    "print(tf.keras.backend.floatx())\n",
    "print(tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet import residual_cnn, memtest_cnn, fp16_loss_generator\n",
    "from data import DataLoader\n",
    "from models.vanilla import vanilla_cnn\n",
    "from models.dense import DenseModel\n",
    "from models.resnet import residual_cnn\n",
    "from models import create_estimator_from_subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading ROI features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\ABCDJJEAN\\analysis\\cnn\\data.py:97: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  skiprows=1),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:done\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"D:\\\\fmri\\\\ABCD\\\\data\"\n",
    "\n",
    "dl = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({dtype('int64'), dtype('float64')}, (8669, 1570))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(dl.vol_labels.dtypes)), dl.vol_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list(dl.vol_labels.dtypes)), dl.vol_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\fmri\\\\ABCD\\\\data\\\\fmriresults01\\\\image03\\\\testing_fns.txt\", \"r\") as f:\n",
    "    t1 = [s.strip().split(\"_\")[0][0:4] + \"_\" + s.strip().split(\"_\")[0][4:] for s in f.readlines()]\n",
    "    \n",
    "with open(\"D:\\\\fmri\\\\ABCD\\\\data\\\\fmriresults01\\\\image03\\\\testing2_fns.txt\", \"r\") as f:\n",
    "    t2 = [s.strip().split(\"_\")[0][0:4] + \"_\" + s.strip().split(\"_\")[0][4:] for s in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D://fmri//ABCD//data/jeff_testing_guids.txt\", \"r\") as f:\n",
    "    test_list = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDAR_INV0GGJJ4H9'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_list) - set(t1 + t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1508\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n"
     ]
    }
   ],
   "source": [
    "for idx in np.where(dl.vol_labels.dtypes == 'O')[0]:\n",
    "    print(idx)\n",
    "    dl.vol_labels.iloc[:, idx] = dl.vol_labels.iloc[:, idx].apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDAR_INV0GGJJ4H9'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_list) - set(dl.vol_labels.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "features, labels = dl.generator_input_fn(file_list=os.path.join(data_dir, \"jeff_overfit_guids.txt\"), batch_size=4, repeat=1)\n",
    "model = DenseModel()\n",
    "\n",
    "logits = model(features, training=True)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(labels, logits)\n",
    "l2 = tf.add_n(model.losses)\n",
    "\n",
    "loss += l2\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "with tf.control_dependencies(model.updates):\n",
    "    grads_and_vars = optimizer.compute_gradients(loss)\n",
    "    train_op = optimizer.apply_gradients(\n",
    "                grads_and_vars, global_step=tf.train.get_global_step())\n",
    "\n",
    "    \n",
    "with tf.name_scope(\"gradients\"):\n",
    "    grad_hist_list = [\n",
    "        tf.summary.histogram(\n",
    "            v.name.replace(\n",
    "                \":\", \"_\") + \"/gradient\", g\n",
    "        ) for g, v in grads_and_vars]\n",
    "with tf.name_scope(\"parameter_hists\"):\n",
    "    histogram_list = [\n",
    "        tf.summary.histogram(\n",
    "            var.name.replace(\":\", \"_\"), var)\n",
    "        for var in tf.trainable_variables()]\n",
    "    \n",
    "    hist_op = tf.summary.merge([grad_hist_list, histogram_list])  # this should plot gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'AddN:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3595511.5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(loss))\n",
    "    sess.run(train_op)\n",
    "#     sess.run(hist_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'image': <tf.Tensor 'IteratorGetNext:1' shape=(?, ?, ?, ?, 1) dtype=float32>,\n",
       "  'volume': <tf.Tensor 'IteratorGetNext:5' shape=(?, 389) dtype=float32>,\n",
       "  'entropy': <tf.Tensor 'IteratorGetNext:0' shape=(?, 389) dtype=float32>,\n",
       "  'mean': <tf.Tensor 'IteratorGetNext:3' shape=(?, 389) dtype=float32>,\n",
       "  'stdev': <tf.Tensor 'IteratorGetNext:4' shape=(?, 389) dtype=float32>},\n",
       " <tf.Tensor 'IteratorGetNext:2' shape=(?, 1) dtype=float32>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels = dl.generator_input_fn(file_list=os.path.join(data_dir, \"jeff_overfit_guids.txt\"), batch_size=4, repeat=1)\n",
    "features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor 'gradients/model/image/conv3d/Conv3D_grad/tuple/control_dependency_1:0' shape=(15, 15, 15, 1, 16) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d/kernel:0' shape=(15, 15, 15, 1, 16) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d/BiasAdd_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d/bias:0' shape=(16,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1/batchnorm/mul_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1/gamma:0' shape=(16,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1/batchnorm/sub_grad/tuple/control_dependency:0' shape=(16,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1/beta:0' shape=(16,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d_1/Conv3D_grad/tuple/control_dependency_1:0' shape=(3, 3, 3, 16, 16) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d_1/kernel:0' shape=(3, 3, 3, 16, 16) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d_1/bias:0' shape=(16,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1_1/batchnorm/mul_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1_1/gamma:0' shape=(16,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1_1/batchnorm/sub_grad/tuple/control_dependency:0' shape=(16,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1_1/beta:0' shape=(16,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d_2/Conv3D_grad/tuple/control_dependency_1:0' shape=(3, 3, 3, 16, 32) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d_2/kernel:0' shape=(3, 3, 3, 16, 32) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d_2/BiasAdd_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d_2/bias:0' shape=(32,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1_2/batchnorm/mul_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1_2/gamma:0' shape=(32,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1_2/batchnorm/sub_grad/tuple/control_dependency:0' shape=(32,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1_2/beta:0' shape=(32,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d_3/Conv3D_grad/tuple/control_dependency_1:0' shape=(3, 3, 3, 32, 64) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d_3/kernel:0' shape=(3, 3, 3, 32, 64) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d_3/BiasAdd_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d_3/bias:0' shape=(64,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1_3/batchnorm/mul_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1_3/gamma:0' shape=(64,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1_3/batchnorm/sub_grad/tuple/control_dependency:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1_3/beta:0' shape=(64,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d_4/Conv3D_grad/tuple/control_dependency_1:0' shape=(3, 3, 3, 64, 64) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d_4/kernel:0' shape=(3, 3, 3, 64, 64) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d_4/BiasAdd_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d_4/bias:0' shape=(64,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1_4/batchnorm/mul_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1_4/gamma:0' shape=(64,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1_4/batchnorm/sub_grad/tuple/control_dependency:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1_4/beta:0' shape=(64,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d_5/Conv3D_grad/tuple/control_dependency_1:0' shape=(3, 3, 3, 64, 64) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d_5/kernel:0' shape=(3, 3, 3, 64, 64) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/conv3d_5/BiasAdd_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/conv3d_5/bias:0' shape=(64,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1_5/batchnorm/mul_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1_5/gamma:0' shape=(64,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/model/image/batch_normalization_v1_5/batchnorm/sub_grad/tuple/control_dependency:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'model/image/batch_normalization_v1_5/beta:0' shape=(64,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/features/dense/MatMul_grad/tuple/control_dependency_1:0' shape=(778, 64) dtype=float32>,\n",
       "  <tf.Variable 'features/dense/kernel:0' shape=(778, 64) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/features/dense/BiasAdd_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>,\n",
       "  <tf.Variable 'features/dense/bias:0' shape=(64,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/readout/dense_1/MatMul_grad/tuple/control_dependency_1:0' shape=(64, 128) dtype=float32>,\n",
       "  <tf.Variable 'readout/dense_1/kernel:0' shape=(64, 128) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/readout/dense_1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(128,) dtype=float32>,\n",
       "  <tf.Variable 'readout/dense_1/bias:0' shape=(128,) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/logits/dense_2/MatMul_grad/tuple/control_dependency_1:0' shape=(128, 1) dtype=float32>,\n",
       "  <tf.Variable 'logits/dense_2/kernel:0' shape=(128, 1) dtype=float32>),\n",
       " (<tf.Tensor 'gradients/logits/dense_2/BiasAdd_grad/tuple/control_dependency_1:0' shape=(1,) dtype=float32>,\n",
       "  <tf.Variable 'logits/dense_2/bias:0' shape=(1,) dtype=float32>)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "features, labels = dl.generator_input_fn(file_list=os.path.join(data_dir, \"jeff_overfit_guids.txt\"), batch_size=4, repeat=1)\n",
    "\n",
    "logits2, end_points, l = vanilla_cnn(features)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(labels, logits2)\n",
    "optimizer = tf.train.AdamOptimizer(0.001, epsilon=0.1)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "train_op = optimizer.apply_gradients(\n",
    "            grads_and_vars, global_step=tf.train.get_global_step())\n",
    "grads_and_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    f = sess.run(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NDAR_INVUY636PFH'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(data_dir, \"jeff_overfit_guids.txt\")) as f:\n",
    "    sid = f.readlines()\n",
    "sid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NDAR_INV007W6H7B', 'NDAR_INV00CY2MDM', 'NDAR_INV00HEV6HB',\n",
       "       'NDAR_INV00LJVZK2', 'NDAR_INV00NPMHND', 'NDAR_INV00X2TBWJ',\n",
       "       'NDAR_INV014RTM1V', 'NDAR_INV019DXLU4', 'NDAR_INV01EN91PG',\n",
       "       'NDAR_INV028D3ELL',\n",
       "       ...\n",
       "       'NDAR_INVZ5BHJRP7', 'NDAR_INVZ95YA2ZB', 'NDAR_INVZCDF5310',\n",
       "       'NDAR_INVZEL29M7N', 'NDAR_INVZHCK39Y1', 'NDAR_INVZM2Y9JCA',\n",
       "       'NDAR_INVZRBMFHKB', 'NDAR_INVZVGAMFG7', 'NDAR_INVZXPAWB32',\n",
       "       'NDAR_INVZZL0VA2F'],\n",
       "      dtype='object', name='subject', length=4154)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.labels.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.784013, 104.25767, 23.995482, ..., nan, nan, nan], dtype=object)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.vol_labels.loc[str(sid[0])].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: parameter_hists/vanilla_model/problem/kernel_0\n\t [[node parameter_hists/vanilla_model/problem/kernel_0 (defined at <ipython-input-147-873a4a50d464>:28) ]]\n\t [[node IteratorGetNext (defined at D:\\GitHub\\ABCDJJEAN\\analysis\\cnn\\data.py:182) ]]\n\nCaused by op 'parameter_hists/vanilla_model/problem/kernel_0', defined at:\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-147-873a4a50d464>\", line 28, in <module>\n    for var in tf.trainable_variables()]\n  File \"<ipython-input-147-873a4a50d464>\", line 28, in <listcomp>\n    for var in tf.trainable_variables()]\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\summary\\summary.py\", line 177, in histogram\n    tag=tag, values=values, name=scope)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 312, in histogram_summary\n    \"HistogramSummary\", tag=tag, values=values, name=name)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: parameter_hists/vanilla_model/problem/kernel_0\n\t [[node parameter_hists/vanilla_model/problem/kernel_0 (defined at <ipython-input-147-873a4a50d464>:28) ]]\n\t [[node IteratorGetNext (defined at D:\\GitHub\\ABCDJJEAN\\analysis\\cnn\\data.py:182) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: parameter_hists/vanilla_model/problem/kernel_0\n\t [[{{node parameter_hists/vanilla_model/problem/kernel_0}}]]\n\t [[{{node IteratorGetNext}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-b7c94aae55e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mgv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: parameter_hists/vanilla_model/problem/kernel_0\n\t [[node parameter_hists/vanilla_model/problem/kernel_0 (defined at <ipython-input-147-873a4a50d464>:28) ]]\n\t [[node IteratorGetNext (defined at D:\\GitHub\\ABCDJJEAN\\analysis\\cnn\\data.py:182) ]]\n\nCaused by op 'parameter_hists/vanilla_model/problem/kernel_0', defined at:\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-147-873a4a50d464>\", line 28, in <module>\n    for var in tf.trainable_variables()]\n  File \"<ipython-input-147-873a4a50d464>\", line 28, in <listcomp>\n    for var in tf.trainable_variables()]\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\summary\\summary.py\", line 177, in histogram\n    tag=tag, values=values, name=scope)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\ops\\gen_logging_ops.py\", line 312, in histogram_summary\n    \"HistogramSummary\", tag=tag, values=values, name=name)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: parameter_hists/vanilla_model/problem/kernel_0\n\t [[node parameter_hists/vanilla_model/problem/kernel_0 (defined at <ipython-input-147-873a4a50d464>:28) ]]\n\t [[node IteratorGetNext (defined at D:\\GitHub\\ABCDJJEAN\\analysis\\cnn\\data.py:182) ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(train_op)\n",
    "    gv = sess.run(grads_and_vars)\n",
    "    sess.run(hist_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"cfgs/vanilla.json\", \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "model_fn, params = create_estimator_from_subclass(VanillaModel, cfg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\numpy\\core\\_methods.py:32: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims, initial)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.6541084,\n",
       " -0.0015102276,\n",
       " -0.2398521,\n",
       " -0.0015124897,\n",
       " -1.0820638,\n",
       " -2.8521754e-08,\n",
       " -0.20531039,\n",
       " -0.10185695,\n",
       " -0.56947744,\n",
       " -3.3527613e-07,\n",
       " -0.14130549,\n",
       " -0.09947908,\n",
       " -0.42093903,\n",
       " -4.5634806e-08,\n",
       " -0.09651737,\n",
       " -0.079591446,\n",
       " -0.25188792,\n",
       " -6.068149e-08,\n",
       " -0.13353615,\n",
       " -0.0793041,\n",
       " -0.5946453,\n",
       " -1.4640391e-06,\n",
       " -1.0094633,\n",
       " -2.2550192,\n",
       " nan,\n",
       " 0.0,\n",
       " -1.1919512,\n",
       " -3.886716,\n",
       " -10.2298765,\n",
       " -20.214798]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[g[0].min() for g in gv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument <tensorflow.python.keras.engine.training.Model object at 0x000002821C96EDD8> has invalid type <class 'tensorflow.python.keras.engine.training.Model'>, must be a string or Tensor. (Can not convert a Model into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 300\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    301\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3477\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3478\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3566\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[1;32m-> 3567\u001b[1;33m                                                            types_str))\n\u001b[0m\u001b[0;32m   3568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a Model into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5ed2d606d0b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1137\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \"\"\"\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    302\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n\u001b[0;32m    303\u001b[0m                         \u001b[1;34m'must be a string or Tensor. (%s)'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m                         (fetch, type(fetch), str(e)))\n\u001b[0m\u001b[0;32m    305\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument <tensorflow.python.keras.engine.training.Model object at 0x000002821C96EDD8> has invalid type <class 'tensorflow.python.keras.engine.training.Model'>, must be a string or Tensor. (Can not convert a Model into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 383)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "#     print(sess.run(labels))\n",
    "    print(sess.run(features[\"volume\"]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"cfgs/dev.json\", \"r\") as f:\n",
    "    cfg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn, params = create_estimator_model(residual_cnn, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute '_losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-7460737f0cc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0me\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_conv\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute '_losses'"
     ]
    }
   ],
   "source": [
    "e[\"initial_conv\"]._losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'D:\\\\fmri\\\\ABCD\\\\Model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001570A5A2208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function create_estimator_model.<locals>.model_fn at 0x00000157094FFA60>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.Estimator(\n",
    "   model_fn=model_fn,\n",
    "   model_dir=\"D:\\\\fmri\\\\ABCD\\\\Model\",\n",
    "   params=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from D:\\fmri\\ABCD\\Model\\model.ckpt-0\n",
      "WARNING:tensorflow:From C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into D:\\fmri\\ABCD\\Model\\model.ckpt.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 547560 values, but the requested shape has 567931\n\t [[{{node Reshape}}]]\n\t [[node IteratorGetNext (defined at D:\\GitHub\\ABCDJJEAN\\analysis\\cnn\\data.py:162) ]]\n\t [[node gradients/model/image/conv3d/Conv3D_grad/Shape (defined at D:\\GitHub\\ABCDJJEAN\\analysis\\cnn\\models\\__init__.py:65) ]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 547560 values, but the requested shape has 567931\n\t [[{{node Reshape}}]]\n\t [[{{node IteratorGetNext}}]]\n\t [[{{node gradients/model/image/conv3d/Conv3D_grad/Shape}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-24f0ed116409>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m classifier.train(\n\u001b[0;32m      2\u001b[0m     \u001b[0minput_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"jeff_overfit_guids.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1171\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1172\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1268\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1270\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1253\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1091\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 547560 values, but the requested shape has 567931\n\t [[{{node Reshape}}]]\n\t [[node IteratorGetNext (defined at D:\\GitHub\\ABCDJJEAN\\analysis\\cnn\\data.py:162) ]]\n\t [[node gradients/model/image/conv3d/Conv3D_grad/Shape (defined at D:\\GitHub\\ABCDJJEAN\\analysis\\cnn\\models\\__init__.py:65) ]]"
     ]
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn = lambda: dl.generator_input_fn(file_list=os.path.join(data_dir, \"jeff_overfit_guids.txt\"), batch_size=4),\n",
    "    steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.losses.get_regularization_loss()))\n",
    "    print(sess.run(losses[\"reg\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.rand(514, 514, 514)\n",
    "dl.cfg[\"crop_size\"][0]\n",
    "center = [s // 2 for s in img.shape]\n",
    "t = img[center[0] - (dl.cfg[\"crop_size\"][0] // 2):center[0] + (dl.cfg[\"crop_size\"][0] // 2) + 1,\n",
    " center[1] - dl.cfg[\"crop_size\"][1] // 2:center[1] + dl.cfg[\"crop_size\"][1] // 2 + 1,\n",
    " center[2] - dl.cfg[\"crop_size\"][2] // 2:center[2] + dl.cfg[\"crop_size\"][2] // 2 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 40)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "257 - 218, 297 - 257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 297)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center[0] - (dl.cfg[\"crop_size\"][0] // 2), center[0] + (dl.cfg[\"crop_size\"][0] // 2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 78, 90, 78, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 72, 84, 72, 8 2752        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 72, 84, 72, 8 0           conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 72, 84, 72, 8 1736        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 72, 84, 72, 8 32          conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 72, 84, 72, 8 0           batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 72, 84, 72, 8 1736        leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 72, 84, 72, 8 32          conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 72, 84, 72, 8 72          leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 72, 84, 72, 8 0           batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 72, 84, 72, 8 0           conv3d_1[0][0]                   \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 36, 42, 36, 8 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 36, 42, 36, 1 3472        max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_2 (Batch (None, 36, 42, 36, 1 64          conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 36, 42, 36, 1 0           batch_normalization_v1_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 36, 42, 36, 1 6928        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 36, 42, 36, 1 64          conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 36, 42, 36, 1 144         max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 36, 42, 36, 1 0           batch_normalization_v1_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 36, 42, 36, 1 0           conv3d_4[0][0]                   \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 18, 21, 18, 1 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 18, 21, 18, 3 13856       max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 18, 21, 18, 3 128         conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 18, 21, 18, 3 0           batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 18, 21, 18, 3 27680       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 18, 21, 18, 3 128         conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 18, 21, 18, 3 544         max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 18, 21, 18, 3 0           batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 18, 21, 18, 3 0           conv3d_7[0][0]                   \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3D)  (None, 9, 10, 9, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 9, 10, 9, 64) 55360       max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 9, 10, 9, 64) 256         conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 9, 10, 9, 64) 0           batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 9, 10, 9, 64) 110656      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 9, 10, 9, 64) 256         conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 9, 10, 9, 64) 2112        max_pooling3d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 9, 10, 9, 64) 0           batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 9, 10, 9, 64) 0           conv3d_10[0][0]                  \n",
      "                                                                 leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3D)  (None, 4, 5, 4, 64)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 4, 5, 4, 128) 221312      max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 4, 5, 4, 128) 512         conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 4, 5, 4, 128) 0           batch_normalization_v1_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 4, 5, 4, 128) 442496      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 4, 5, 4, 128) 512         conv3d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 4, 5, 4, 128) 8320        max_pooling3d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 4, 5, 4, 128) 0           batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 5, 4, 128) 0           conv3d_13[0][0]                  \n",
      "                                                                 leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d (Globa (None, 128)          0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          66048       global_average_pooling3d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            513         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 967,721\n",
      "Trainable params: 966,729\n",
      "Non-trainable params: 992\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = vanilla_cnn(dl.cfg[\"crop_size\"] + [1])\n",
    "model.compile(tf.train.AdamOptimizer(0.005), \"MSE\")\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'D:\\\\fmri\\\\ABCD\\\\output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000228D43E3828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.keras.estimator.model_to_estimator(\n",
    "    keras_model=model,\n",
    "    model_dir=\"D:\\\\fmri\\\\ABCD\\\\output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The dictionary passed into features does not have the expected inputs keys defined in the keras model.\\n\\tExpected keys: {'input_1'}\\n\\tfeatures keys: {'stdev', 'image', 'volume', 'mean', 'entropy'}\\n\\tDifference: {'input_1', 'image', 'stdev', 'volume', 'mean', 'entropy'}\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b445f71e7f6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msaving_listeners\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1152\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1154\u001b[1;33m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1155\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(features, labels, mode)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     model = _clone_and_build_model(mode, keras_model, custom_objects, features,\n\u001b[1;32m--> 278\u001b[1;33m                                    labels)\n\u001b[0m\u001b[0;32m    279\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[1;34m(mode, keras_model, custom_objects, features, labels)\u001b[0m\n\u001b[0;32m    184\u001b[0m   \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m   input_tensors, target_tensors = _convert_estimator_io_to_keras(\n\u001b[1;32m--> 186\u001b[1;33m       keras_model, features, labels)\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m   \u001b[0mcompile_clone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36m_convert_estimator_io_to_keras\u001b[1;34m(keras_model, features, labels)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m   input_tensors = _to_ordered_tensor_list(\n\u001b[1;32m--> 159\u001b[1;33m       features, input_names, 'features', 'inputs')\n\u001b[0m\u001b[0;32m    160\u001b[0m   target_tensors = _to_ordered_tensor_list(\n\u001b[0;32m    161\u001b[0m       labels, output_names, 'labels', 'outputs')\n",
      "\u001b[1;32mC:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36m_to_ordered_tensor_list\u001b[1;34m(obj, key_order, obj_name, order_name)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0morder_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[0mobj_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                 different_keys=different_keys))\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_convert_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_order\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The dictionary passed into features does not have the expected inputs keys defined in the keras model.\\n\\tExpected keys: {'input_1'}\\n\\tfeatures keys: {'stdev', 'image', 'volume', 'mean', 'entropy'}\\n\\tDifference: {'input_1', 'image', 'stdev', 'volume', 'mean', 'entropy'}\""
     ]
    }
   ],
   "source": [
    "estimator.train(\n",
    "    lambda: dl.generator_input_fn(file_list=os.path.join(data_dir, \"jeff_training_guids.txt\"),\n",
    "                                  batch_size=32, shuffle_buffer=100, repeat=1),\n",
    "    hooks=None,\n",
    "    steps=100,\n",
    "    max_steps=None,\n",
    "    saving_listeners=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_loss = fp16_loss_generator(tf.keras.losses.binary_crossentropy, multiplier=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\miccai-abcd\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "gen = create_testing_generator(input_shape)\n",
    "dataset = tf.data.Dataset.from_generator(gen, \n",
    "                                         output_types=(tf.float16, tf.int64), \n",
    "                                         output_shapes=(tf.TensorShape(input_shape), tf.TensorShape([])))\n",
    "dataset = dataset.batch(1)\n",
    "next_batch = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     a = sess.run(next_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 128, 96, 1)    0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 82, 114, 82, 32)   108032    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 82, 114, 82, 32)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 82, 114, 82, 32)   351264    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 82, 114, 82, 32)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 41, 57, 41, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 41, 57, 41, 64)    256064    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 41, 57, 41, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 20, 28, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 20, 28, 20, 128)   1024128   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 20, 28, 20, 128)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 10, 14, 10, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 14, 10, 256)   4096256   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 10, 14, 10, 256)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 5, 7, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 5, 7, 5, 256)      8192256   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 5, 7, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,036,257\n",
      "Trainable params: 14,036,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph()\n",
    "\n",
    "m = memtest_cnn(input_shape, tf.float16)\n",
    "# m = residual_cnn(input_shape, tf.float16)\n",
    "custom_loss = fp16_loss_generator(tf.keras.losses.binary_crossentropy, multiplier=1)\n",
    "m.compile(tf.train.GradientDescentOptimizer(0.005), custom_loss)\n",
    "\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 76s 8s/step - loss: 0.6889\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.6990\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.7006\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.6937\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.6930\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.6942\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.6949\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.6943\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.6939\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.6937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c86bdd2748>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# with tf.Session(config=config) as sess:\n",
    "m.fit(dataset, epochs=10, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 959ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "575.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(dataset, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(dataset, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(gen())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(np.reshape(test, [1] + input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 128, 96, 1)    0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 82, 114, 82, 32)   108032    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 82, 114, 82, 32)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 82, 114, 82, 32)   351264    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 82, 114, 82, 32)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 41, 57, 41, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 41, 57, 41, 64)    256064    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 41, 57, 41, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 20, 28, 20, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 20, 28, 20, 128)   1024128   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 20, 28, 20, 128)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 10, 14, 10, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 14, 10, 256)   4096256   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 10, 14, 10, 256)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 5, 7, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 5, 7, 5, 256)      8192256   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 5, 7, 5, 256)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d (Gl (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,036,257\n",
      "Trainable params: 14,036,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_floatx('float32')\n",
    "tf.keras.backend.set_epsilon(1e-7)\n",
    "\n",
    "# m = residual_cnn(input_shape, tf.float32)\n",
    "\n",
    "m = memtest_cnn(input_shape, tf.float32)\n",
    "\n",
    "m.compile(tf.train.GradientDescentOptimizer(0.05), tf.keras.losses.binary_crossentropy)\n",
    "\n",
    "m.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 57s 6s/step - loss: 6.6731\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 7s 716ms/step - loss: 11.2827\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 7s 717ms/step - loss: 6.4472\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 7s 716ms/step - loss: 9.6709\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 7s 717ms/step - loss: 9.6709\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 7s 718ms/step - loss: 6.4472\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 7s 743ms/step - loss: 11.2827\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 7s 729ms/step - loss: 6.4472\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 7s 716ms/step - loss: 9.6709\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 7s 717ms/step - loss: 6.4472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28129b48c50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# with tf.Session(config=config) as sess:\n",
    "m.fit(dataset, epochs=10, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6256953477859497"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(dataset, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miccai-abcd",
   "language": "python",
   "name": "miccai-abcd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
